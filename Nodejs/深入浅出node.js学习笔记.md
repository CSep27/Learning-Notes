待整理

《深入浅出 Node.js》朴灵

# 第 2 章 模块机制

## 2.4 C/C++扩展模块

- 编译完成后，hello.node 文件会生成在 build/Release 目录下。

- C/C++扩展模块与 JavaScript 模块的区别在于加载之后不需要编译，直接执行之后就可以被外部调用了，其加载速度比 JavaScript 模块略快。

## 2.6 包与 NPM

- 全局模式这个称谓其实并不精确，-g 是将一个包安装为全局可用的可执行命令。

- 它根据包描述文件中的 bin 字段配置，将实际脚本链接到与 Node 可执行文件相同的路径下。

- 事实上，通过全局模式安装的所有模块包都被安装进了一个统一的目录下，这个目录可以通过如下方式推算出来：`path.resolve(process.execPath, '..', '..', 'lib', 'node_modules');​​`

- 如果 Node 可执行文件的位置是/usr/local/bin/node，那么模块目录就是/usr/local/lib/node_modules。最后，通过软链接的方式将 bin 字段配置的可执行文件链接到 Node 的可执行目录下。

# 第 3 章 异步 I/O

- Node 演变为一个可以基于它构建各种高速、可伸缩网络应用的平台，

- Nginx 采用纯 C 编写，性能表现非常优异。它们的区别在于，Nginx 具备面向客户端管理连接的强大能力，但是它的背后依然受限于各种同步方式的编程语言。但 Node 却是全方位的，既可以作为服务器端去处理客户端带来的大量并发请求，也能作为客户端向网络中的各个应用进行并发请求。

## 3.1 为什么要异步 I/O

- I/O 是昂贵的,分布式 I/O 是更昂贵的。

## 3.2 异步 I/O 实现现状

- 此处非阻塞 I/O 与阻塞 I/O 的区别在于阻塞 I/O 完成整个获取数据的过程，而非阻塞 I/O 则不带数据直接返回，要获取数据，还需要通过文件描述符再次读取。

- 为了获取完整的数据，应用程序需要重复调用 I/O 操作来确认是否完成。这种重复调用判断操作是否完成的技术叫做轮询。

- 通过让部分线程进行阻塞 I/O 或者非阻塞 I/O 加轮询技术来完成数据获取，让一个线程进行计算处理，通过线程之间的通信将 I/O 得到的数据进行传递，这就轻松实现了异步 I/O

- **我们时常提到 Node 是单线程的，这里的单线程仅仅只是 JavaScript 执行在单线程中罢了。在 Node 中，无论是\*nix 还是 Windows 平台，内部完成 I/O 任务的另有线程池。**

## 3.3 Node 的异步 I/O

- 每个事件循环中有一个或者多个观察者，而判断是否有事件要处理的过程就是向这些观察者询问是否有要处理的事件。

- 在 Windows 下，这个循环基于 IOCP 创建，而在\*nix 下则基于多线程创建。

- 事实上，从 JavaScript 发起调用到内核执行完 I/O 操作的过渡过程中，存在一种中间产物，它叫做请求对象。

- JavaScript 线程可以继续执行当前任务的后续操作。当前的 I/O 操作在线程池中等待执行，不管它是否阻塞 I/O，都不会影响到 JavaScript 线程的后续执行，如此就达到了异步的目的。

- 请求对象是异步 I/O 过程中的重要中间产物，所有的状态都保存在这个对象中，包括送入线程池等待执行以及 I/O 操作完毕后的回调处理。

- 线程池中的 I/O 操作调用完毕之后，会将获取的结果储存在 req->result 属性上，然后调用 PostQueuedCompletionStatus()通知 IOCP，告知当前对象操作已经完成：

- **事件循环、观察者、请求对象、I/O 线程池**这四者共同构成了 Node 异步 I/O 模型的基本要素。

- Linux 下通过 epoll 实现这个过程，FreeBSD 下通过 kqueue 实现，Solaris 下通过 Event ports 实现。不同的是线程池在 Windows 下由内核（IOCP）直接提供，\*nix 系列下由 libuv 自行实现。

- **在 Node 中，除了 JavaScript 是单线程外，Node 自身其实是多线程的，只是 I/O 线程使用的 CPU 较少。另一个需要重视的观点则是，除了用户代码无法并行执行外，所有的 I/O（磁盘 I/O 和网络 I/O 等）则是可以并行起来的。**

## 3.4 非 I/O 的异步 API

- 它们的实现原理与异步 I/O 比较类似，只是不需要 I/O 线程池的参与。调用 setTimeout()或者 setInterval()创建的定时器会被插入到定时器观察者内部的一个红黑树中。每次 Tick 执行时，会从该红黑树中迭代取出定时器对象，检查是否超过定时时间，如果超过，就形成一个事件，它的回调函数将立即执行。

- 定时器的问题在于，它并非精确的（在容忍范围内）。

- 而事实上，采用定时器需要动用红黑树，创建定时器对象和迭代等操作，而 setTimeout(fn, 0)的方式较为浪费性能。

- 每次调用 process.nextTick()方法，只会将回调函数放入队列中，在下一轮 Tick 时取出执行。定时器中采用红黑树的操作时间复杂度为 O(lg(n)), nextTick()的时间复杂度为 O(1)。相较之下，process.nextTick()更高效。

- setImmediate()方法与 process.nextTick()方法十分类似，都是将回调函数延迟执行。

- process.nextTick()中的回调函数执行的优先级要高于 setImmediate()。这里的原因在于事件循环对观察者的检查是有先后顺序的，process.nextTick()属于 idle 观察者，setImmediate()属于 check 观察者。在每一个轮循环检查中，idle 观察者先于 I/O 观察者，I/O 观察者先于 check 观察者。

- process.nextTick()的回调函数保存在一个数组中，setImmediate()的结果则是保存在链表中。

- 在行为上，process.nextTick()在每轮循环中会将数组中的回调函数全部执行完，而 setImmediate()在每轮循环中执行链表中的一个回调函数。

- 之所以这样设计，是为了保证每轮循环能够较快地执行结束，防止 CPU 占用过多而阻塞后续 I/O 调用的情况。

## 3.5 事件驱动与高性能服务器

- Node 通过事件驱动的方式处理请求，无须为每一个请求创建额外的对应线程，可以省掉创建线程和销毁线程的开销，同时操作系统在调度任务时因为线程较少，上下文切换的代价很低。

- Node 具有与 Nginx 相同的特性，不同之处在于 Nginx 采用纯 C 写成，性能较高，但是它仅适合于做 Web 服务器，用于反向代理或负载均衡等服务，在处理具体业务方面较为欠缺。Node 则是一套高性能的平台，可以利用它构建与 Nginx 相同的功能，也可以处理各种具体业务，而且与背后的网络保持异步畅通。两者相比，Node 没有 Nginx 在 Web 服务器方面那么专业，但场景更大，自身性能也不错。

## 4.1 函数式编程

- 高阶函数则是可以把函数作为参数，或是将函数作为返回值的函数

- 偏函数用法是指创建一个调用另外一个部分——参数或变量已经预置的函数——的函数的用法。

## 4.2 异步编程的优势与难点

- 事件循环模型需要应对海量请求，海量请求同时作用在单线程上，就需要防止任何一个计算耗费过多的 CPU 时间片。至于是计算密集型，还是 I/O 密集型，只要计算不影响异步 I/O 的调度，那就不构成问题。建议对 CPU 的耗用不要超过 10 ms，或者将大量的计算分解为诸多的小量计算，通过 setImmediate()进行调度。

- 尝试对异步方法进行 try/catch 操作只能捕获当次事件循环内的异常，对 callback 执行时抛出的异常将无能为力。

## 4.3 异步编程解决方案

- 所谓雪崩问题，就是在高访问量、大并发量的情况下缓存失效的情景，此时大量的请求同时涌入数据库中，数据库无法同时承受如此大的查询请求，进而往前影响到网站整体的响应速度。

- 这里我们利用了 once()方法，将所有请求的回调都压入事件队列中，利用其执行一次就会将监视器移除的特点，保证每一个回调只会被执行一次。

- 对于相同的 SQL 语句，保证在同一个查询开始到结束的过程中永远只有一次。SQL 在进行查询时，新到来的相同调用只需在队列中等待数据就绪即可，一旦查询结束，得到的结果可以被这些调用共同使用。这种方式能节省重复的数据库调用产生的开销。由于 Node 单线程执行的原因，此处无须担心状态同步问题。这种方式其实也可以应用到其他远程调用的场景中，即使外部没有缓存策略，也能有效节省重复开销。

- 事件发布/订阅模式有着它的优点。利用高阶函数的优势，侦听器作为回调函数可以随意添加和删除，它帮助开发者轻松处理随时可能添加的业务逻辑。也可以隔离业务逻辑，保持业务逻辑单元的职责单一。

- 由于多个异步场景中回调函数的执行并不能保证顺序，且回调函数之间互相没有任何交集，所以需要借助一个第三方函数和第三方变量来处理异步协作的结果。

- Promise 操作只会处在 3 种状态的一种：未完成态、完成态和失败态。

- Promise 是高级接口，事件是低级接口。低级接口可以构成更多更复杂的场景，高级接口一旦定义，不太容易变化，不再有低级接口的灵活性，但对于解决典型问题非常有效。

## 5.1 V8 的垃圾回收机制与内存限制

- 在 Node 中通过 JavaScript 使用内存时就会发现只能使用部分内存（64 位系统下约为 1.4 GB,32 位系统下约为 0.7 GB）

- 在这样的限制下，将会导致 Node 无法直接操作大内存对象，比如无法将一个 2 GB 的文件读入内存中进行字符串分析处理，即使物理内存有 32 GB。这样在单个 Node 进程的情况下，计算机的内存资源无法得到充足的使用。

- 造成这个问题的主要原因在于 Node 基于 V8 构建，所以在 Node 中使用的 JavaScript 对象基本上都是通过 V8 自己的方式来进行分配和管理的。

- 在 V8 中，所有的 JavaScript 对象都是通过堆来进行分配的。

- 当我们在代码中声明变量并赋值时，所使用对象的内存就分配在堆中。如果已申请的堆空闲内存不够分配新的对象，将继续申请堆内存，直到堆的大小超过 V8 的限制为止。

- 深层原因是 V8 的垃圾回收机制的限制。按官方的说法，以 1.5 GB 的垃圾回收堆内存为例，V8 做一次小的垃圾回收需要 50 毫秒以上，做一次非增量式的垃圾回收甚至要 1 秒以上。这是垃圾回收中引起 JavaScript 线程暂停执行的时间，在这样的时间花销下，应用的性能和响应能力都会直线下降。

- V8 的垃圾回收策略主要基于分代式垃圾回收机制。

- 现代的垃圾回收算法中按对象的存活时间将内存的垃圾回收进行不同的分代，然后分别对不同分代的内存施以更高效的算法。

- 在 V8 中，主要将内存分为新生代和老生代两代。新生代中的对象为存活时间较短的对象，老生代中的对象为存活时间较长或常驻内存的对象。

- V8 堆的整体大小就是新生代所用内存空间加上老生代的内存空间。

- 前面我们提及的`--max-old-space-size` 命令行参数可以用于设置老生代内存空间的最大值，`--max-new-space-size` （最新版本文档已经没有这个值了，有一个`--max-semi-space-size`设置）命令行参数则用于设置新生代内存空间的大小的。比较遗憾的是，这两个最大值需要在启动时就指定。这意味着 V8 使用的内存没有办法根据使用情况自动扩充，当内存分配过程中超过极限值时，就会引起进程出错。

- 在分代的基础上，新生代中的对象主要通过 Scavenge 算法进行垃圾回收。

- Cheney 算法是一种采用复制的方式实现的垃圾回收算法。它将堆内存一分为二，每一部分空间称为 semispace。在这两个 semispace 空间中，只有一个处于使用中，另一个处于闲置状态

- 实际使用的堆内存是新生代中的两个 semispace 空间大小和老生代所用内存大小之和。

- 当一个对象经过多次复制依然存活时，它将会被认为是生命周期较长的对象。这种较长生命周期的对象随后会被移动到老生代中，采用新的算法进行管理。对象从新生代中移动到老生代中的过程称为晋升

- 对象晋升的条件主要有两个，一个是对象是否经历过 Scavenge 回收，一个是 To 空间的内存占用比超过限制。

- V8 在老生代中主要采用了 Mark-Sweep 和 Mark-Compact 相结合的方式进行垃圾回收。

- Mark-Sweep 是标记清除的意思，它分为标记和清除两个阶段

- Mark-Sweep 在标记阶段遍历堆中的所有对象，并标记活着的对象，在随后的清除阶段中，只清除没有被标记的对象。

- Mark-Sweep 最大的问题是在进行一次标记清除回收后，内存空间会出现不连续的状态。

- Mark-Compact 是标记整理的意思，是在 Mark-Sweep 的基础上演变而来的。它们的差别在于对象在标记为死亡后，在整理的过程中，将活着的对象往一端移动，移动完成后，直接清理掉边界外的内存。

- v8 主要使用 Mark-Sweep，在空间不足以对从新生代中晋升过来的对象进行分配时才使用 Mark-Compact。

- 为了避免出现 JavaScript 应用逻辑与垃圾回收器看到的不一致的情况，垃圾回收的 3 种基本算法都需要将应用逻辑暂停下来，待执行完垃圾回收后再恢复执行应用逻辑，这种行为被称为“全停顿”（stop-the-world）。

- 为了降低全堆垃圾回收带来的停顿时间，V8 先从标记阶段入手，将原本要一口气停顿完成的动作改为增量标记（incremental marking），也就是拆分为许多小“步进”，每做完一“步进”就让 JavaScript 应用逻辑执行一小会儿，垃圾回收与应用逻辑交替执行直到标记阶段完成

- V8 后续还引入了延迟清理（lazy sweeping）与增量式整理（incremental compaction），让清理与整理动作也变成增量式的

- 垃圾回收是影响性能的因素之一。想要高性能的执行效率，需要注意让垃圾回收尽量少地进行，尤其是全堆垃圾回收。

- 查看垃圾回收日志的方式主要是在启动时添加--trace_gc 参数

- 通过在 Node 启动时使用--prof 参数，可以得到 V8 执行时的性能分析数据，其中包含了垃圾回收执行时占用的时间

## 5.2 高效使用内存

- 如果需要释放常驻内存的对象，可以通过 delete 操作来删除引用关系。或者将变量重新赋值，让旧的对象脱离引用关系。

- 虽然 delete 操作和重新赋值具有相同的效果，但是在 V8 中通过 delete 删除对象的属性有可能干扰 V8 的优化，所以通过赋值方式解除引用更好。

- 在 JavaScript 中，实现外部作用域访问内部作用域中变量的方法叫做闭包（closure）。

- 问题在于，一旦有变量引用这个中间函数，这个中间函数将不会释放，同时也会使原始的作用域不会得到释放，作用域中产生的内存占用也不会得到释放。除非不再有引用，才会逐步释放。

## 5.3 内存指标

- 调用 process.memoryUsage()可以看到 Node 进程的内存占用情况，

- rss 是 resident set size 的缩写，即进程的常驻内存部分

- heapTotal 是堆中总共申请的内存量，heapUsed 表示目前堆中使用中的内存量。这 3 个值的单位都是字节。

- os 模块中的 totalmem()和 freemem()这两个方法用于查看操作系统的内存使用情况，它们分别返回系统的总内存和闲置内存，以字节为单位。

- 通过 process.memoryUsage()的结果可以看到，堆中的内存用量总是小于进程的常驻内存用量，这意味着 Node 中的内存使用并非都是通过 V8 进行分配的。我们将那些不是通过 V8 分配的内存称为堆外内存。

- 这其中的原因是 Buffer 对象不同于其他对象，它不经过 V8 的内存分配机制，所以也不会有堆内存的大小限制。这意味着利用堆外内存可以突破内存限制的问题。

- Node 的内存构成主要由通过 V8 进行分配的部分和 Node 自行分配的部分。受 V8 的垃圾回收限制的主要是 V8 的堆内存。

## 5.4 内存泄漏

- 通常，造成内存泄漏的原因有如下几个：

  - 缓存。
  - 队列消费不及时。
  - 作用域未释放。

- JavaScript 开发者通常喜欢用对象的键值对来缓存东西，但这与严格意义上的缓存又有着区别，严格意义的缓存有着完善的过期策略，而普通对象的键值对并没有。

- 在 Node 中，任何试图拿内存当缓存的行为都应当被限制。当然，这种限制并不是不允许使用的意思，而是要小心为之。

- 记录键在数组中，一旦超过数量，就以先进先出的方式进行淘汰。

- 由于模块的缓存机制，模块是常驻老生代的。在设计模块时，要十分小心内存泄漏的出现。

- 如果模块不可避免地需要这么设计，那么请添加清空队列的相应接口，以供调用者释放内存。

- 直接将内存作为缓存的方案要十分慎重。除了限制缓存的大小外，另外要考虑的事情是，进程之间无法共享内存。如果在进程内使用缓存，这些缓存不可避免地有重复，对物理内存的使用是一种浪费。

- 目前比较好的解决方案是采用进程外的缓存，进程自身不存储状态。外部的缓存软件有着良好的缓存过期淘汰策略以及自有的内存管理，不影响 Node 进程的性能。

  1. 将缓存转移到外部，减少常驻内存的对象的数量，让垃圾回收更高效。
  2. 进程之间可以共享缓存。

- 深度的解决方案应该是监控队列的长度，一旦堆积，应当通过监控系统产生报警并通知相关人员。另一个解决方案是任意异步调用都应该包含超时机制，一旦在限定的时间内未完成响应，通过回调函数传递超时异常，使得任意异步调用的回调都具备可控的响应时间，给消费速度一个下限值。

- 启用超时模式时，调用加入到队列中就开始计时，超时就直接响应一个超时错误。启用拒绝模式时，当队列拥塞时，新到来的调用会直接响应拥塞错误。这两种模式都能够有效地防止队列拥塞导致的内存泄漏问题。

## 5.5 内存泄漏排查

- 如果经过连续 5 次垃圾回收后，内存仍然没有被释放，这意味着有内存泄漏的产生，node-memwatch 会出发一个 leak 事件

## 5.6 大内存应用

- process 模块中的 stdin 和 stdout 则分别是可读流和可写流的示例。

- 由于 V8 的内存限制，我们无法通过 fs.readFile()和 fs.writeFile()直接进行大文件的操作，而改用 fs.createReadStream()和 fs.createWriteStream()方法通过流的方式实现对大文件的操作

- 可读流提供了管道方法 pipe()，封装了 data 事件和写入操作。通过流的方式，上述代码不会受到 V8 内存限制的影响，有效地提高了程序的健壮性。

- 如果不需要进行字符串层面的操作，则不需要借助 V8 来处理，可以尝试进行纯粹的 Buffer 操作，这不会受到 V8 堆内存的限制。但是这种大片使用内存的情况依然要小心，即使 V8 不限制堆内存的大小，物理内存依然有限制。

## 6.1 Buffer 结构

- Buffer 是一个像 Array 的对象，但它主要用于操作字节。

- Buffer 是一个典型的 JavaScript 与 C++结合的模块，它将性能相关部分用 C++实现，将非性能相关的部分用 JavaScript 实现

- 第 5 章揭示了 Buffer 所占用的内存不是通过 V8 分配的，属于堆外内存。

- Buffer 对象类似于数组，它的元素为 16 进制的两位数，即 0 到 255 的数值。

- 给元素的赋值如果小于 0，就将该值逐次加 256，直到得到一个 0 到 255 之间的整数。如果得到的数值大于 255，就逐次减 256，直到得到 0~255 区间内的数值。如果是小数，舍弃小数部分，只保留整数部分。

- Buffer 对象的内存分配不是在 V8 的堆内存中，而是在 Node 的 C++层面实现内存的申请的。为此 Node 在内存的使用上应用的是在 C++层面申请内存、在 JavaScript 中分配内存的策略。

- 简单而言，slab 就是一块申请好的固定大小的内存区域。slab 具有如下 3 种状态。

  - full：完全分配状态。
  - partial：部分分配状态。
  - empty：没有被分配状态。

- Node 以 8 KB 为界限来区分 Buffer 是大对象还是小对象：
- ​​​​​​​​​​Buffer.poolSize = 8 \* 1024;​​
- 这个 8 KB 的值也就是每个 slab 的大小值，在 JavaScript 层面，以它作为单位单元进行内存的分配。

- 上面提到的 Buffer 对象都是 JavaScript 层面的，能够被 V8 的垃圾回收标记回收。但是其内部的 parent 属性指向的 SlowBuffer 对象却来自于 Node 自身 C++中的定义，是 C++层面上的 Buffer 对象，所用内存不在 V8 的堆中。

- 简单而言，真正的内存是在 Node 的 C++层面提供的，JavaScript 层面只是使用它。当进行小而频繁的 Buffer 操作时，采用 slab 的机制进行预先申请和事后分配，使得 JavaScript 到操作系统之间不必有过多的内存申请方面的系统调用。对于大块的 Buffer 而言，则直接使用 C++层面提供的内存，而无需细腻的分配操作。

## 6.3 Buffer 的拼接

- data 事件中获取的 chunk 对象即是 Buffer 对象

- 这里潜藏的问题在于如下这句代码：
- ​​​​​​​​​​data += chunk;​​
- 这句代码里隐藏了 toString()操作，它等价于如下的代码：
- ​​​​​​​​​​data = data.toString() + chunk.toString();​​

- 对于任意长度的 Buffer 而言，宽字节字符串都有可能存在被截断的情况，只不过 Buffer 的长度越大出现的概率越低而已，但该问题依然不可忽视。

- StringDecoder 在得到编码后，知道宽字节字符串在 UTF-8 编码下是以 3 个字节的方式存储的，所以第一次 write()时，只输出前 9 个字节转码形成的字符，“月”字的前两个字节被保留在 StringDecoder 实例内部。第二次 write()时，会将这 2 个剩余字节和后续 11 个字节组合在一起，再次用 3 的整数倍字节进行转码。于是乱码问题通过这种中间形式被解决了。

- 正确的拼接方式是用一个数组来存储接收到的所有 Buffer 片段并记录下所有片段的总长度，然后调用 Buffer.concat()方法生成一个合并的 Buffer 对象。

- Buffer.concat()方法封装了从小 Buffer 对象向大 Buffer 对象的复制过程，

## 6.4 Buffer 与性能

- Web 应用中，字符串转换到 Buffer 是时时刻刻发生的，提高字符串到 Buffer 的转换效率，可以很大程度地提高网络吞吐率。

- 通过预先转换静态内容为 Buffer 对象，可以有效地减少 CPU 的重复使用，节省服务器资源。

- 在 Node 构建的 Web 应用中，可以选择将页面中的动态内容和静态内容分离，静态内容部分可以通过预先转换为 Buffer 的方式，使性能得到提升。由于文件自身是二进制数据，所以在不需要改变内容的场景下，尽量只读取 Buffer，然后直接传输，不做额外的转换，避免损耗。

## 9.2 多进程架构

- send()方法在将消息发送到 IPC 管道前，将消息组装成两个对象，一个参数是 handle，另一个是 message。

- 发送到 IPC 管道中的实际上是我们要发送的句柄文件描述符，文件描述符实际上是一个整数值。这个 message 对象在写入到 IPC 管道时也会通过 JSON.stringify()进行序列化。所以最终发送到 IPC 通道中的信息都是字符串，send()方法能发送消息和句柄并不意味着它能发送任意对象。

- 子进程根据 message.type 创建对应 TCP 服务器对象，然后监听到文件描述符上。

- Node 进程之间只有消息传递，不会真正地传递对象，这种错觉是抽象封装的结果。

- TCP 服务器端 socket 套接字的文件描述符并不相同，导致监听到相同的端口时会抛出异常。

- 由于独立启动的进程互相之间并不知道文件描述符，所以监听相同端口时就会失败。但对于 send()发送的句柄还原出来的服务而言，它们的文件描述符是相同的，所以监听相同端口不会引起异常

- 多个应用监听相同端口时，文件描述符同一时间只能被某个进程所用。换言之就是网络请求向服务器端发送时，只有一个幸运的进程能够抢到连接，也就是说只有它能为这个请求进行服务。这些进程服务是抢占式的。

## 9.3 集群稳定之路

- 一旦有异常出现，主进程会创建新的工作进程来为用户服务，旧的进程一旦处理完已有连接就自动断开。

- 对于 Node 而言，需要分清的是它的繁忙是由 CPU、I/O 两个部分构成的，影响抢占的是 CPU 的繁忙度。对不同的业务，可能存在 I/O 繁忙，而 CPU 较为空闲的情况

- 这种新的策略叫 Round-Robin，又叫轮叫调度。轮叫调度的工作方式是由主进程接受连接，将其依次分发给工作进程。

- 我们将这种用来发送通知和查询状态是否更改的进程叫做通知进程。为了不混合业务逻辑，可以将这个进程设计为只进行轮询和通知，不处理任何业务逻辑，

- 进程在启动时从通知服务处除了读取第一次数据外，还将进程信息注册到通知服务处。一旦通过轮询发现有数据更新后，根据注册信息，将更新后的数据发送给工作进程。

## 9.4 Cluster 模块

- 建议用 cluster.setupMaster()这个 API，将主进程和工作进程从代码上完全剥离，

- 对于自行通过 child_process 来操作时，则可以更灵活地控制工作进程，甚至控制多组工作进程。其原因在于自行通过 child_process 操作子进程时，可以隐式地创建多个 TCP 服务器，使得子进程可以共享多个的服务器端 socket

## 9.5 总结

- 这符合 Unix 的设计理念，每个进程只做一件事，并做好一件事，将复杂分解为简单，将简单组合成强大。

## 第 10 章 测试

- 测试的意义在于，在用户消费产出的代码之前，开发者首先消费它，给予其重要的质量保证

- 测试包含单元测试、性能测试、安全测试和功能测试等几个方面

## 10.1 单元测试

- 如果 API 升级时，测试用例可以很好地检查是否向下兼容。对于各种可能的输入，一旦测试覆盖，都能明确它的输出。代码改动后，可以通过测试结果判断代码的改动是否影响已确定的结果。

- 断言就是单元测试中用来保证最小单元是否正常的检测方法。

- 断言用于检查程序在运行时是否满足期望。

- 现今流行的单元测试风格主要有 TDD（测试驱动开发）和 BDD（行为驱动开发）两种

- 测试用例最少需要通过正向测试和反向测试来保证测试对功能的覆盖，这是最基本的测试用例

- 在测试代码时，我们通常通过 require 引入 lib 目录下的文件进行测试。但是为了得到测试覆盖率，必须在运行测试用例时执行编译之后的代码。

- 模拟异步方法时，我们调用 process.nextTick()使得回调方法能够异步执行即可

- rewire 模块提供了一种巧妙的方式实现对私有方法的访问。

- 每一个被 rewire 引入的模块都有**set**()和**get**()方法。它巧妙地利用了闭包的诀窍，在 eval()执行时，实现了对模块内部局部变量的访问，从而可以将局部变量导出给测试用例调用执行。

## 10.2 性能测试

- benchmark 模块并不是简单地统计执行多少次测试代码后对比时间，它对测试有着严密的抽样过程。执行多少次方法取决于采样到的数据能否完成统计。

- 对网络接口做压力测试需要考查的几个指标有吞吐率、响应时间和并发数，这些指标反映了服务器的并发处理能力

  - Requests per second：这是我们重点关注的一个值，它表示服务器每秒能处理多少请求，是重点反映服务器并发能力的指标。这个值又称 RPS 或 QPS。

## 11.1 项目工程化

- 项目工程化过程中，最基本的几步是目录结构、构建工具、编码规范和代码审查等

## 11.2 部署流程

- 预发布环境与普通的测试环境的差别在于它的数据较为接近线上真实的数据。

- 进程在启动时将进程 ID 写入到一个 pid 文件中，这个文件可以存放在一个约定的路径下，如应用的 run/app.pid。

## 11.3 性能

- 对于 Web 应用而言，最直接有效的莫过于动静分离、多进程架构、分布式，其中涉及的几个拆分原则如下所示。

  - ❑ 做专一的事。
  - ❑ 让擅长的工具做擅长的事情。
  - ❑ 将模型简化。
  - ❑ 将风险分离。

- 缓存

- 但是 Node 处理静态文件的能力并不算突出。将图片、脚本、样式表和多媒体等静态文件都引导到专业的静态文件服务器上，让 Node 只处理动态请求即可

- 是故能够在动态内容中再将动态内容和静态内容分离，还能进一步提升性能，

- 但这种程度上的控制也许没有普适性，需

- 要较多细节处理。

- 提升性能其实差不多只有两个途经，一是提升服务的速度，二是避免不必要的计算

- 读写分离，这主要针对数据库而言

## 11.4 日志

- 在健全的系统中，完善的日志记录最能够还原问题现场。通过记录日志来定位问题是一种成本较小的方式。这种非结构化、轻量的记录方式容易实现，也容易扩展。

- console 模块在具体实现时，log 与 info 方法都将信息输出给标准输出 process.stdout, warn 与 error 方法则将信息输出到标准错误 process.stderr，而 info 和 error 分别是 log 和 warn 的别名

- 对于回调函数中产生的异常，则可以不用过问，交给全局的 uncaughtException 事件去捕获即可。

- 通常的 API 编写而言，尽量不要隐藏错误，不要通过 try/catch 块将异常捕获，然后隐藏起来不向外部调用者暴露。这对于底层 API 的设计而言，尤为重要。

- 我的建议是异常尽量由最上层的调用者捕获记录，底层调用或中间层调用中出现的异常只要正常传递给上层的调用方即可。

- 但是对于最上层的业务，不能无视下层传递过来的任何异常，需要记录异常，以便将来排查错误，同时应该对用户给出友好的提示

- 最好在记录异常时有良好的的格式和更详细的数据。为此可以准备一个 format()方法来封装和格式化异常信息，

- 对于未捕获的异常，Node 提供了机制以免进程直接退出，但是发生未捕获异常的进程也不能继续在线上进行服务了，因为可能有内存泄

- 漏的风险产生

- 将日志分析和日志记录这两个步骤分离开来是较好的选择。日志记录可以在线写，日志分析则可以借助一些工具同步到数据库中，通过离线分析的方式反馈出来。

- 对于 Console 对象，它的内部属性\_stdout 和\_stderr 就是指向我们传入的两个输入流对象的。在设计的过程中，我们可以按日期传递对应的日志文件可写流对象，为此可以设计一个定时器用于当日期发生更改时，更改日志对象的两个输入流对象即可。

## 11.5 监控报警

- 应用的监控主要有两类，一种是业务逻辑型的监控，一种是硬件型的监控。监控主要通过定时采样来进

- 行记录。除此之外，还要对监控的信息设置上限，一旦出现大的波动，就需要发出警报提醒开发者。为了较好地供开发者使用，监控到的信息一般还要通过数据可视化的方式反映出来，以便更直观地查看。

- 健康的系统响应时间应该是波动较小的、持续均衡的。

- 健康的内存使用应当是有升有降，在访问量大的时候上升，在访问量回落的时候，占用量也随之回落。

- CPU 的使用分为用户态、内核态、IOWait 等

- 如果用户态 CPU 使用率较高，说明服务器上的应用需要大量的 CPU 开销；如果内核态 CPU 使用率较高，说明服务器

- 花费大量时间进行进程调度或者系统调用；IOWait 使用率则反应的是 CPU 等待磁盘 I/O 操作。

- CPU 的使用率中，用户态小于 70%、内核态小于 35%且整体小于 70%时，处于健康状态。

- CPU load 又称 CPU 平均负载，它用来描述操作系统当前的繁忙程度，可以简单地理解为 CPU 在单位时间内正在使用和等待使用 CPU 的平均任务数。

- I/O 负载指的主要是磁盘 I/O。反应的是磁盘上的读写情况，

- 最简单的状态反馈就是给监控响应一个时间戳，监控方检查时间戳是否正常即可

- 健壮一些的状态响应则是将应用的依赖项的状态打印出来，如数据库连接是否正常、缓存是否正常等。

## 11.7 异构共存

- 其原理在于能够服务化的产品，都是具有标准协议的。协议几乎是解决异构系统最完美的方案。只要有标准的交互协议，各种语言就能通过网络与之进行交互。

## 11.8 总结

- 用 Node 也是一样，随着开发的进展、涉及层面的增多，我们看到在产品的角度要解决的问题依然是大部分技术都要解决的问题

## 附录 B 调试 Node

- Node 的调试直接受益于 V8。V8 提供了标准的调试 API，使得可以从进程内部进行调试。同时还提供了基于该 API 的 TCP 调试协议，使得通过调试协议，可以从进程外进行代码调试。Node 内建了调试协议的客户端，所以在启动时带上 debug 参数就可以实现对 JavaScript 代码的调试。
