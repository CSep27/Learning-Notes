# 说明

掘金小册《从 0 到 1 落地前端工程化》学习笔记

第 12-16 章

# 第 12 章 数据管理： MongoDB

MongoDB 是一个功能丰富的 NoSQL 数据库，其使用 JSON 管理数据，就像 JS 操作 JSON 一样方便。

## 搭建数据库

### 安装

打开[MongoDB 的下载地址](https://www.mongodb.com/try/download/community)，按照服务器类型选择相应版本 tgz 包，复制下载链接。

登录服务器，进入`/opt`目录，执行`wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel80-7.0.5.tgz`

下载后解压`tar -zxvf mongodb-linux-x86_64-rhel80-7.0.5.tgz`

重命名文件夹`mv mongodb-linux-x86_64-rhel80-7.0.5 mongodb`

### 配置

创建文件夹与日志文件`cd mongodb && mkdir data && mkdir log && touch log/mongodb.log`

设置环境变量`echo "export PATH=$PATH:/opt/mongodb/bin" >> ~/.bash_profile && source ~/.bash_profile`

> `cat .bash_profile`查看内容`export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/var/lib/snapd/snap/bin:/root/bin:/opt/mongodb/bin`，可以看到在后面新增了`:/opt/mongodb/bin`，`$PATH` 指当前已经设置的环境变量。`export PATH=$PATH:/opt/mongodb/bin`这一句就是在已经设置的环境变量后面新增内容。

执行`vim /opt/mongodb/mongodb.conf`，加入以下内容。该文件作为 MongoDB 的配置文件，在执行 mongod 时必须指定配置文件的路径。

```bash
# 数据库
dbpath=/opt/mongodb/data
# 日志文件
logpath=/opt/mongodb/log/mongodb.log
# 使用追加的方式更新日志
logappend=true
# 端口
port=27017
# 以守护进程的方式运行MongoDB(创建服务器进程)
fork=true
# 启用用户验证
# auth=true
# 绑定服务IP(绑定127.0.0.1只能本机访问，若不指定则默认本地所有IP)
bind_ip=0.0.0.0
```

执行 `mongod -f /opt/mongodb/mongodb.conf` 启动 MongoDB，输出以下信息表示开启成功。

```bash
about to fork child process, waiting until server is ready for connections.
forked process: 862873
child process started successfully, parent exiting
```

执行`ps -ef | grep mongod`查看 MongoDB 状态，输出以下信息表示 MongoDB 正常运行。

```bash
root      862873       1  1 16:50 ?        00:00:00 mongod -f mongodb.conf
root      863179  862001  0 16:51 pts/1    00:00:00 grep --color=auto mongod
```

执行`mongod --shutdown -f /opt/mongodb/mongodb.conf`关闭 MongoDB，输出以下信息表示关闭成功。

```bash
Killing process with pid: 862873
```

若无使用 MongoDB 的应用在运行，请关闭 MongoDB，这样才能让服务器在 CPU 低占用的情况下保持稳定的性能。当用到 MongoDB 时再开启。

### 连接

小册中执行`mongon`连接 mongodb，但是我执行之后提示`-bash: mongo: command not found`。网上说 6.0 之前的版本才有这个命令（小册用的 5.0.6 版本）。高版本（当前使用 7.0.5）不支持，需要自行安装 mongodb shell。

下载`wget https://downloads.mongodb.com/compass/mongosh-2.1.5-linux-x64.tgz`，解压到`/opt`安装，设置软链接。执行`mongosh`，打印如下内容，连接上了 mongodb 数据库。

```bash
Current Mongosh Log ID:	65dab73100aa6dfa278dcacc
Connecting to:		mongodb://127.0.0.1:27017/?directConnection=true&serverSelectionTimeoutMS=2000&appName=mongosh+2.1.5
Using MongoDB:		7.0.5
Using Mongosh:		2.1.5

For mongosh info see: https://docs.mongodb.com/mongodb-shell/

# ... etc.

test >
```

- `show dbs` 查看所有数据库。
- `use admin`切换到 admin 数据库，该数据库是 MongoDB 的默认数据库，用于管理用户权限。
- 执行`db.createUser()`命令为 admin 数据库创建 root 用户。

```bash
test> show dbs
admin   40.00 KiB
config  84.00 KiB
local   72.00 KiB
test> use admin
switched to db admin
admin> db.createUser({ user: "root", pwd: "123456", roles: [{ role: "root", db: "admin" }] })
{ ok: 1 }
admin>
```

执行`vim /opt/mongodb/mongodb.conf`将`# auth=true`的注释去掉，重启 MongoDB。

`mongod --shutdown -f /opt/mongodb/mongodb.conf`

`mongod -f /opt/mongodb/mongodb.conf`

`mongosh`

执行以下命令，输出 1 表示用户登录成功。接着可基于 MongoDB 操作数据了。

```bash
test> use admin
switched to db admin
admin> db.auth("root", "123456")
{ ok: 1 }
admin>
```

#### 通过 GUI 工具 MongoDB Compass 连接

打开 Compass，填写一条 MongoDB 标准 URL 连接数据库。

MongoDB 标准 URL 是 MongoDB 基于 shell 命令连接数据库的标准化 URL，由以下参数组成。

`mongodb://username:password@host:port/database[?options]`

- mongodb:// 协议 可理解成 HTTP
- username 账号 上述创建的 root
- password 密码 上述创建的 root 的密码 123456
- host 实例公有 IP 云服务器 IP
- port 端口 默认 27017
- database 数据库 上述切换的 admin 数据库
- options 配置 用得很少

拼接起来的 URL 就是`mongodb://root:123456@aaa.bbb.ccc.ddd:27017/admin`

在腾讯云的服务器页面，点击防火墙配置，添加一条规则，放行 27017 端口，之后成功通过 Compass 登录。

### 开发

在 Node 环境中结合 mongoose 开发一个小型接口系统，通过 Nginx 代理接口，输出一个可基于 HTTPS 访问的接口系统。

![小型接口系统](./images/interface-system.awebp)

#### mongoose

mongoose 是一个在 Node 环境中操作 MongoDB 对象模型的 npm 模块。

mongoose 中有三个很重要的概念，分别是 Schema、Model 和 Entity。

- Schema: 表示模式，一种以文档形式存储的数据库模型骨架，不具备数据库操作能力
- Model: 表示模型，由 Schema 生成的模型，具备抽象属性与数据库操作能力
- Entity: 表示实例，由 Model 创建的实例，具备操作数据库操作能力

mongoose 中任何事物都要从 Schema 开始。每个 Schema 对应 MongoDB 中的一个集合 Collection。Schema 中定义了集合中文档 Document 的格式。

通过 Schema 为产品数据定义一个模式，再通过 Model 为产品模式定义一个模型。

其中每个产品数据都使用 type 定义数据类型，其类型值只能使用以下有效类型。String、Number、Boolean、Array 和 Date 为原生数据类型，无需引用可直接使用。Buffer 为 Node 的特有数据类型，可查看 Node Buffer。ObjectId 与 Mixed 为 mongoose 定义的数据类型。ObjectId 表示主键，每个 Schema 都会默认配置该属性，键值为\_id，在数据入库时会自动创建。Mixed 表示混合类型，可认为是引用类型的对象 Object。

在开发接口时，需做到以下细节才能保障数据的准确性、安全性、可靠性和稳定性。

- 校验全部字段是否为空
- 校验全部字段是否符合正则
- 根据某个字段判断文档是否存在
- 读写数据库

在创建时 mongoose 会动态分析名称的词法，对不是复数的单词会追加 s 或 es 的后缀，所以在使用 model()定义一个模型时，建议采用单词的单数形式。

#### data-base 项目

依赖：`npm i @yangzw/bruce-us cross-env dayjs koa koa-body koa-json koa-logger koa-onerror koa-router mongoose`

结构：

```txt
database # 项目代码
├── node_modules
├── src
│		├── database # 通过 Mongoose 连接到 mongodb 数据库，connected、disconnected、error时打印日志
│		├── models # 定义 Mongoose 需要的 model
│		├── routes # koa项目路由，处理不同动作的url
│		├					 # 对数据进行各种判断之后，对数据库进行增删改查操作，用到 models 中定义的 model
│		├── utils  # 工具代码
│		├── app.config.js # 配置：连接mongodb的配置（host，password等）；服务接口前缀
│		├── index.js # 服务入口：启动 node 服务；导入database和router；koa的body，json，logger,error等处理
├── package.json
├── package-loac.json
└── ...
```

database/index.js

```js
import Mongoose from "mongoose";

import AppConfig from "../app.config";

const { connect, connection } = Mongoose;
const {
  mongodb: { host, password, port, username },
} = AppConfig;

connect(`mongodb://${username}:${password}@${host}:${port}/mall`, {
  authSource: "admin",
  useNewUrlParser: true,
  useUnifiedTopology: true,
});
connection.on("connected", () => console.log("数据库连接成功"));
connection.on("disconnected", () => console.log("数据库连接断开"));
connection.on("error", () => console.log("数据库连接异常"));
```

models/product.js

```js
import Day from "dayjs";
import Mongoose from "mongoose";

const { model, Schema } = Mongoose;

// 定义模式
const Product = {
	brand: {
		match: /^.{2,200}$/,
		msg: "品牌只能由2到200位任意字符组成",
		required: true,
		trim: true,
		type: String
	},
	code: {
		match: /^[A-Za-z0-9]{4,30}$/,
		msg: "条形码只能由4到30位英文或数字组成",
		required: true,
		trim: true,
		type: String
	},
	createtime: { ... },
	description: { ... },
	name: { ... }
	origin: { ... }
};
// 定义模型
const ProductModel = model("product", new Schema(Product, { versionKey: false }));

export {
	Product,
	ProductModel
};
```

routes/product/create.js

```js
import KoaRouter from "koa-router";
import { AsyncTo } from "@yangzw/bruce-us/dist/node";

import { Product, ProductModel } from "../../models";
import { CheckData } from "../../utils/setting";
import AppConfig from "../../app.config";

const Router = KoaRouter();

Router.post(`${AppConfig.publicPath}/product/create`, async (ctx) => {
  const params = ctx.request.body;
  // 校验全部字段是否为空
  if (!CheckData(params, 5)) {
    ctx.body = { code: 300, msg: "产品信息都不能为空" };
    return false;
  }
  // 校验全部字段是否符合正则
  const checkMsg = Object.entries(params).reduce((t, v) => {
    const { match, msg } = Product[v[0]];
    return !t && !match.test(v[1]) ? { code: 400, msg } : t;
  }, "");
  if (checkMsg) {
    ctx.body = checkMsg;
    return false;
  }
  // 判断产品是否存在
  const [err1, res1] = await AsyncTo(
    ProductModel.findOne({ code: params.code })
  );
  if (err1) {
    ctx.body = { code: 400, msg: "新增产品失败" };
    return false;
  }
  if (res1) {
    ctx.body = { code: 400, msg: "当前产品已存在" };
    return false;
  }
  // 新增产品
  const [err2, res2] = await AsyncTo(ProductModel.create(params));
  if (!err2 && res2) {
    ctx.body = { code: 200, data: res2, msg: "新增产品成功" };
  } else {
    ctx.body = { code: 400, msg: "新增产品失败" };
  }
});

export default Router;
```

index.js

```js
import Koa from "koa";
import KoaBody from "koa-body";
import KoaJson from "koa-json";
import KoaLogger from "koa-logger";
import KoaOnerror from "koa-onerror";

import "./database";
import Router from "./routes";

// 创建实例
const app = new Koa();
KoaOnerror(app); // 美化错误参数
app.on("error", (err, ctx) => console.error("server error", err, ctx)); // 捕获错误

// 配置中间件
app.use(KoaLogger()); // 日志解析
app.use(KoaBody({ multipart: true })); // Body解析
app.use(KoaJson()); // JSON解析

// 匹配路由
Object.values(Router).forEach((v) => app.use(v.routes(), v.allowedMethods()));

// 监听服务
app.listen(3000);
console.log("Node服务已启动，监听端口3000");
```

### 调试：测试接口可行性

本地启动服务后，使用 Postman 新增一条数据。

或者通过 curl 新增一条数据，数据需要按照必填项以及校验规则构造，否则会报错。

```bash
% curl -d 'brand=emma&code=123abc&description=lalala&name=test&origin=ooo' http://localhost:3000/product/create
{
  "code": 200,
  "data": {
    "brand": "emma",
    "code": "123abc",
    "createtime": "2024-02-25 17:30:07",
    "description": "lalala",
    "name": "test",
    "origin": "ooo",
    "_id": "65db08fde0ee519210a8db3e"
  },
  "msg": "新增产品成功"
}
```

刷新 MongoDB Compass 可以看到 DataBase 中新增一个 Mall 数据库，并且多了 products collection，products 的 documents 中有一条数据。

MongoDB 中如果存在某个数据库则使用它，不存在则自动创建。

## 部署：发布到服务器

二级域名 api.csep.chat 该域名用于托管所有接口系统。前面已经用 express 项目部署过。

下面是小册部署内容：

若托管的接口系统有三个，分别是商城接口系统 mall、博客接口系统 blog 和简历接口系统 resume，那应以前缀区分它们。

- 商城接口系统：https://api.yangzw.vip/mall/xyz，Node服务监听端口为3000
- 博客接口系统：https://api.yangzw.vip/blog/xyz，Node服务监听端口为3001
- 简历接口系统：https://api.yangzw.vip/resume/xyz，Node服务监听端口为3002

修改`vim /etc/nginx/conf.d/api.yangzw.vip.conf`：

```bash
server {
	server_name api.yangzw.vip;
	location /mall {
		proxy_pass http://127.0.0.1:3000;
		proxy_set_header Host $host;
		proxy_set_header X-Forwarded-For $remote_addr;
		proxy_set_header X-Forwarded-Proto https;
	}
	location /blog {
		proxy_pass http://127.0.0.1:3001;
		proxy_set_header Host $host;
		proxy_set_header X-Forwarded-For $remote_addr;
		proxy_set_header X-Forwarded-Proto https;
	}
	location /resume {
		proxy_pass http://127.0.0.1:3002;
		proxy_set_header Host $host;
		proxy_set_header X-Forwarded-For $remote_addr;
		proxy_set_header X-Forwarded-Proto https;
	}
}
```

执行`certbot --nginx`，选择二级域名`api.yangzw.vip`，给二级域名添加证书。

# 第 13 章 进程管理：Node 服务常驻后台

监控 Node 服务的运行状态可用以下工具解决。

- forever
- pm2

## pm2

pm2 是一个运行在 Node 环境的守护进程管理器，用于管理 Node 进程。

1. 后台运行 pm2 启动的 Node 进程，不会随着 CMD 工具的关闭而结束。
2. 代码监听 监听代码文件，若发生改动会重启 Node 进程。
3. 次数限制 限制不稳定的重启次数，达到上限就结束 Node 进程。
4. 零秒重启 在集群模式中，可做到重启时不会结束 Node 进程。
5. 负载均衡 在集群模式中，自动使用轮询方式达到负载均衡，减轻服务器压力。
6. 实时接口 提供 Node 进程监控状态的实时接口，返回服务器与 Node 进程的相关信息。
7. 日志管理 收集的日志文件可配合插件管理与细化。
8. 集成管理 对于多个 Node 进程，在不同环境中可通过同一个配置文件统一管理。

### 字段

字段 功能 参数 描述

- id 服务 ID ~ 自动以递增方式生成
- name 服务名称 ~ 通过--name 设置
- mode 进程模式 fork/cluster 单个进程或多个进程
- ↺ 重启次数 ~ 自动记录
- status 进程在线 online/stopped 在线或停止
- cpu cpu 占用率 ~ 自动记录
- memory 内存占用大小 ~ 自动记录

### 命令

- `pm2 restart <name	id	all>` 重启进程
- `pm2 reload <name	id	all>` 重载进程
- `pm2 stop <name	id	all>` 停止进程
- `pm2 delete <name	id	all>` 杀死进程
- `pm2 show <name	id>` 查看进程信息
- `pm2 ls` 查看进程列表
- `pm2 monit` 查看面板信息
- `pm2 logs` 查看进程日志信息

### 指标

执行`pm2 show <name|id>`输出更多进程信息

- restarts 表示重启次数
- uptime 表示运行时间
- script path 表示启动入口文件
- script args 表示启动入口文件的附带参数
- error log path 表示错误日志路径
- out log path 表示输出日志路径
- exec mode 表示进程模式
- watch & reload 表示是否开启监听文件变动重启
- unstable restarts 表示不稳定的重启次数。
- used heap size 表示堆内存使用情况
- heap usage 表示堆内存使用率
- heap size 表示堆内存
- event loop latency 表示事件循环时延。

执行`pm2 monit`查看面板信息：

左上角是进程列表，右上角是全部实时日志，左下角是选中进程的代码指标，右下角是进程信息。左右方向键切换面板，上下方向键滚动当前面板内容。

### 注意事项

改造启动命令为：`pm2 start npm --name data-base --watch --max-memory-restart 300 -- run start`

- --name 给 node 进程指定 name，方便区分。
- --watch 开启监听文件变动重启
- --max-memory-restart 设置当内存占用率超过阈值自动重启。
- -- run start 使用 `pm2 start` 执行 `npm run start`，就是将其拆分为 `npm` 与 `run start`，将第一部分存放到 `pm2 start` 后，将第二部分使用`--`连接并存放到末尾。

# 第 14 章 应用打包体积过大：Webpack 构建策略

主要是两个层面

- 减少打包时间：缩减范围、缓存副本、定向搜索、提前构建、并行构建、可视结构
- 减少打包体积：分割代码、摇树优化、动态垫片、按需加载、作用提升、压缩资源

## 减少打包时间

### 缩减范围

配置 include/exclude 缩小 Loader 对文件的搜索范围，避免不必要的转译

### 缓存副本

配置 cache 缓存 Loader 对文件的编译副本，再次编译时只编译变动的文件。

很多 Loader/Plugin 都会提供一个可用编译缓存的选项，通常包括 cache 字眼。

### 提前构建

配置 DllPlugin 将第三方依赖提前打包，将 DLL 与业务代码完全分离且每次只构建业务代码。

在 webpack v2 时已存在，不过现在 webpack v4+已不推荐使用该配置，因为其版本迭代带来的性能提升足以忽略 DllPlugin 所带来的效益。

DLL 意为动态链接库，指一个可由多个程序同时使用的代码库。在前端领域中可认为是另类缓存的存在，它把公共代码打包为 dll 文件并存放到硬盘中，再次构建时动态链接 dll 文件就无需再次打包那些公共代码，以提升构建速度，减少打包时间。

可用 autodll-webpack-plugin 代替手动配置。

### 并行构建

配置 Thread 将 Loader 单进程转换为多进程，释放 CPU 多核并发的优势。

thread-loader 根据 CPU 个数开启线程。

若项目文件不算多就不要使用该性能优化建议，毕竟开启多个线程也会存在性能开销。

### 可视结构

配置 BundleAnalyzer 分析打包文件结构，找出导致体积过大的原因。通过分析原因得出优化方案减少打包时间。

## 减少打包体积

### 分割代码

分割各个模块代码，提取相同部分代码，减少重复代码的出现频率。webpack v4+使用 splitChunks 替代 CommonsChunksPlugin 实现代码分割。

### Tree Shaking

删除项目中未被引用代码。

摇树优化只对 ESM 生效，对其他模块规范失效。**摇树优化针对静态结构分析**，只有 import/export 才能提供静态的导入/导出功能，因此在编写业务代码时必须使用 ESM 才能让摇树优化删除重复代码与未使用代码。

### 动态垫片

通过垫片服务根据 UA 返回当前浏览器代码垫片。无需将繁重的代码垫片打包进去。每次构建都配置@babel/preset-env 与 core-js 根据某些需求将 Polyfill 打包进来，这无疑又为代码体积增加了贡献。

@babel/preset-env 提供的 useBuiltIns 可按需导入 Polyfill。

- false：无视 target.browsers 将所有 Polyfill 加载进来
- entry：根据 target.browsers 将部分 Polyfill 加载进来(仅引入有浏览器不支持的 Polyfill，需在入口文件 import "core-js/stable")
- usage：根据 target.browsers 与检测代码中 ES6 的使用情况将部分 Polyfill 加载进来(无需在入口文件 import "core-js/stable")

动态垫片可根据浏览器 UserAgent 返回当前浏览器 Polyfill，其思路是根据浏览器的 UserAgent 从 browserlist 中查找出当前浏览器哪些 API 缺乏支持以返回这些 API 的 Polyfill。（可查看 polyfill-library 与 polyfill-service 的源码）。

动态垫片服务：

- [官方 CDN 服务](https://polyfill.io/v3/polyfill.js)
- [阿里 CDN 服务](https://polyfill.alicdn.com/polyfill.js)

  2024.02.26 使用 Chrome 版本 122.0.6261.69（正式版本） (x86_64)，是当前最新版本 Chrome，访问这两个网站

第一个显示不需要 polyfills

```js
/*
 * Polyfill service v3.111.0
 * For detailed credits and licence information see https://polyfill.io.
 *
 * Features requested: default
 *
 */

/* No polyfills needed for current settings and browser */
```

第二个返回了 283KB 的未压缩 js 文件内容，感觉没有按照浏览器动态返回。

使用 html-webpack-tags-plugin 在打包时自动加入动态垫片，同时注释掉@babel/preset-env 相关配置。

```js
import HtmlTagsPlugin from "html-webpack-tags-plugin";

export default {
  // ...
  plugins: [
    // ...
    new HtmlTagsPlugin({
      append: false, // 在生成资源后加入
      publicPath: false, // 使用公共路径
      tags: ["https://polyfill.alicdn.com/polyfill.min.js"], // 资源路径
    }),
  ],
};
```

### 按需加载

将路由页面/触发性功能单独打包为一个文件，使用时才加载，减轻首屏渲染的负担。

### 作用提升

分析模块间依赖关系，把打包好的模块合并到一个函数中，减少函数声明与内存花销。

在未开启作用提升前，构建好的代码会存在大量函数闭包。因为模块依赖，通过 webpack 打包后会转换为 IIFE，大量函数闭包包裹代码会导致打包体积增大，模块越多越明显。在运行代码时创建的函数作用域变多，导致更大的内存开销。

在开启作用提升后，构建好的代码会根据引用顺序放到一个函数作用域中，通过适当重命名某些变量以防止变量名冲突，以减少函数声明与内存花销。

在 webpack 中只需将打包环境设置为生产环境就能让作用提升生效，或显式设置 concatenateModules。

### 压缩资源

压缩 HTML/CSS/JS 代码，压缩字体/图像/音频/视频，更有效减少打包体积。

注：webpack 打包优化后续再专门学习，重点关注下这里提到的之前不了解的点：动态垫片和作用提升。

# 第 15 章 类库打包

项目前期准备工作：合理规划项目结构、按需编写构建代码、批量创建入口文件、按需封装工具函数等。

对于单一类型单一功能的项目，使用 rollup 打包代码会更好，而 rollup 也是为 JS 类库打包而生。

## rollup

与 webpack 偏向于应用打包的定位不同，rollup 更专注于类库打包。

### 基于 Rollup 搭建类库基建模板

开发工具库需解决问题：

- 使用何种模块规范编写工具库源码
- 基于何种运行环境打包工具库庅
- 按照何种分类方式划分工具库源码为不同模块
- 在编辑器中引用工具库时如何模糊提示 函数名称与入参
- 明确工具库源码输出多少种模块规范的 bundle 文件
- 配置 package.json 哪些字段让打包工具自动识别入口文件

#### 初始项目骨架

执行`npm info <pkg>`确认包名没人使用

配置`.gitignore` `.npmignore` (还有`.gitattributes`)

（看 vue 源码没有忽略 lock.json）

```
.DS_Store
node_modules
package-lock.json
yarn.lock
```

package.json

- keywords Npm 搜索功能就是基于该字段查找相同或相似 Npm 模块

```json
{
  "name": "bruce-us",
  "version": "1.0.0",
  "description": "A Web/Node General Util Set",
  "keywords": [],
  "license": "MIT",
  "dependencies": {},
  "devDependencies": {}
}
```

#### 规划源码结构

明确 bundle 文件的运行环境。Web 代码输出一个文件，Node 代码输出一个文件，对于一些既能在 Web 中运行也能在 Node 中运行的代码需单独抽离出来输出一个文件。bundle 文件最终的模块规范确定为 CJS、ESM 和 UMD。

推荐使用 typescript 编写工具库，在打包代码时顺便生成 d.ts 声明文件。这样模块的函数名称与入参都有对应模糊提示，VSCode 会扫描该模块 package.json 的 types 字段，该字段引用一个 d.ts 声明文件，该文件描述类库代码块的相关声明信息，能为 VSCode 提供类型检查等特性功能。

对于一个双环境工具库，可将目录规划为以下结构：

```txt
bruce-us
├─ src
│  ├─ common
│  ├─ node
│  ├─ web
│  ├─ node.ts
│  ├─ web.ts
│  └─ web.umd.ts
├─ .gitignore
├─ .npmignore
└─ package.json
```

也就是把相同的部分放到 common(必须是 web 和 node 都能使用的部分)，不同的部分分开放（web 和 node）。像 vue 源码中，shared 文件夹是共享的部分，platforms 里存放不同平台不同的部分。

#### 完善打包配置

#### 支持多模块打包

导出数组配置，每个模块配置为对象

vue 源码中多平台多模块的配置统一放在 scripts/config.js 中

#### 使用 ts

tsconfig.json typescript 的编译配置。

设置`"declaration": true,`ts 在编译时会自动生成.d.ts。`"declarationDir": "dist"`指定.d.ts 文件的输出地址。

借助插件`rollup-plugin-dts`合并声明文件，。在 src 文件夹中创建 index.ts，收集所有 Web 与 Node 的工具函数。即导入所有工具函数然后统一导出，最终只生成一份声明文件 index.d.ts。

vue 源码中，如果一个文件导出的内容很多，并且全部要导出的话，可以在 index.ts 中这样写：

```ts
export * from "./common/index";
export * from "./node/index";
export * from "./web/index";
```

##### rollup 插件

- @rollup/plugin-typescript，使用该插件编译 typescript。
- @rollup/plugin-node-resolve，使用该插件自动寻找引用到的 Npm 模块。
- @rollup/plugin-commonjs，使用该插件将 CJS 转换为 ESM 再让其参与到后续编译中
- rollup-plugin-cleandir，使用这些插件分别在打包前清理 dist 文件夹
- rollup-plugin-terser 压缩输出代码。
- rollup-plugin-dts，使用该插件合并声明文件

最终 rollup.config.js：

```js
import CommonjsPlugin from "@rollup/plugin-commonjs";
import NodeResolvePlugin from "@rollup/plugin-node-resolve";
import TypescriptPlugin from "@rollup/plugin-typescript";
import { cleandir as CleandirPlugin } from "rollup-plugin-cleandir";
import DtsPlugin from "rollup-plugin-dts";
import { terser as TerserPlugin } from "rollup-plugin-terser";

// 统一使用插件功能
const PLUGINS = [
  NodeResolvePlugin(),
  CommonjsPlugin(),
  TypescriptPlugin(),
  TerserPlugin({
    compress: { drop_console: false },
    format: { comments: false },
  }),
];

// 多模块数组
export default [
  {
    input: "src/web.ts",
    output: { file: "dist/web.js", format: "cjs" },
    plugins: [...PLUGINS, CleandirPlugin("dist")],
  },
  {
    input: "src/web.ts",
    output: { file: "dist/web.esm.js", format: "esm" },
    plugins: PLUGINS,
  },
  {
    input: "src/web.umd.ts",
    output: { file: "dist/web.umd.js", format: "umd", name: "BruceUs" },
    plugins: PLUGINS,
  },
  {
    input: "src/node.ts",
    output: { file: "dist/node.js", format: "cjs" },
    plugins: PLUGINS,
  },
  {
    input: "src/node.ts",
    output: { file: "dist/node.esm.js", format: "esm" },
    plugins: PLUGINS,
  },
  // ts统一一个入口文件，生成一份声明文件index.d.ts
  {
    input: "src/index.ts",
    output: { file: "dist/index.d.ts", format: "esm" },
    plugins: [DtsPlugin()],
  },
];
```

在 package.json 中指定 main 与 types，分别指向默认入口文件与默认声明文件。当引用或打包该 Npm 模块时会直接使用 main 指向的入口文件，当 VSCode 开启类型检验时会直接使用 types 指向的声明文件。

这些自己在封装库的过程中大部分都清楚了，现在相当于再梳理一遍，之前是摸索着一步步做，比如不同模块类型打包以前没考虑到，后来在实践中发现需要支持不同模块类型。ts 这块自己写了代码但是没有生成`.d.ts`，试试能自动生成？

# 第 16 章 单元测试：保障运行质量

## 单元测试

单元测试指检查与验证软件中最小可测试单元。对于单元测试中单元定义，一般来说要根据实际情况判定其具体含义。

单元就是人为规定最小的被测功能模块。单元测试是软件开发时要进行的最低级别测试活动，独立单元将在与程序其他部分隔离的情况下进行测试。

单元测试有两个很重要的概念函数，分别是 expect()与 test()。expect()表示期望得到的运行结果，简称期望结果；test()表示测试结果是否通过预期，简称通过状态。

自动化测试就是编写一些测试函数，通过测试函数运行业务代码，判断实际结果与期望结果是否相符，是则通过，否则不通过，整个过程都是通过预设脚本自动化处理。

### 基于 Jest 为类库编写测试用例

#### 安装

`npm i -D @types/jest jest ts-jest` 安装 jest，同时需要安装 ts 相关依赖

根目录创建`jest.config.js`用于 jest 配置，主要用到的配置选项包括 preset 与 testEnvironment。preset 表示预设模板，使用安装好的 ts-jest 模板；testEnvironment 表示测试环境，可选 web/node。

ts-jest 为 jest 与 typescript 环境中的单元测试提供类型检查支持与预处理。

```js
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
};
```

scripts 中加入测试命令。--no-cache 表示每次启动测试脚本不使用缓存；--watchAlls 表示监听所有单元测试，若发生更新则重新执行脚本。

```json
{
  "scripts": {
    "test": "jest --no-cache --watchAll"
  }
}
```

在 tsconfig.json 中指定 types，加入@types/jest。@types/jest 提供了 expect()与 test()，这样测试文件中使用这两个函数就不会报错未定义了。

如果配置了 typeRoots，那么 types 配置里直接写"jest"。

```json
{
  "compilerOptions": {
    "types": ["@types/jest"]
    /* "typeRoots": ["node_modules/@types", "typings"],
    "types": ["jest"] */
  },
  "exclude": ["jest.config.js"]
}
```

#### 编写单元测试文件

在根目录中创建 test 文件夹。test 文件夹内部的目录结构可参照 src 文件夹，保持源码与测试脚本的目录结构一样，方便后续迭代与维护。单元测试的测试用例使用 xyz.spec.ts 的方式命名。rollup 识别入口文件无需加入对应测试用例文件。

在 test 文件夹中创建 index.spec.ts 文件，加入以下内容。打开 CMD 工具，执行 npm run test，输出以下信息表示测试通过。

```ts
function Sum(...vals: number[]): number {
  return vals.reduce((t, v) => t + v, 0);
}

test("期望结果是6", () => {
  expect(Sum(1, 2, 3)).toBe(6);
});
```

```bash
 PASS  test/index.spec.ts (6.746 s)
 PASS  test/common/array.spec.ts (6.784 s)

Test Suites: 2 passed, 2 total
Tests:       2 passed, 2 total
Snapshots:   0 total
Time:        7.955 s
Ran all test suites.

Watch Usage: Press w to show more.
```

#### 代码覆盖测试

代码覆盖测试指程序源码被测试的比例与程度的所得比例。代码覆盖测试生成的指标称为代码覆盖率，它作为一个指导性指标，可在一定程度上反应测试的完备程度，是软件质量度量的重要手段。**100%覆盖率的代码并不意味着 100%无 Bug**，代码覆盖率作为质量目标无任何意义，应把它作为一种发现未被测试覆盖的代码的检查手段。简而言之，代码覆盖测试更注重测试过程，而测试结果只是测试过程的一个表现。

jest 本身内置代码覆盖测试。修改 jest.config.js 的配置，追加 coverage 相关配置。修改 package.json 中 scripts 的 test，追加--coverage。

```js
module.exports = {
  // Jest 输出coverage files的文件夹
  coverageDirectory: "coverage",
  coverageProvider: "v8",
  coverageThreshold: {
    global: {
      branches: 100,
      functions: 100,
      lines: 100,
      statements: 100,
    },
  },
  preset: "ts-jest",
  testEnvironment: "node",
};
```

```json
{
  "scripts": {
    "test": "jest --no-cache --watchAll --coverage"
  }
}
```

覆盖率测试输出：

```bash
----------|---------|----------|---------|---------|-------------------
File      | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s
----------|---------|----------|---------|---------|-------------------
All files |       0 |        0 |       0 |       0 |
----------|---------|----------|---------|---------|-------------------
```

参数的含义：

| 参数    | 说明       | 描述               |
| ------- | ---------- | ------------------ |
| %Stmts  | 语句覆盖率 | 是否每个语句都执行 |
| %Branch | 分支覆盖率 | 是否每个条件都执行 |
| %Funcs  | 函数覆盖率 | 是否每个函数都调用 |
| %Lines  | 行覆盖率   | 是否每行代码都执行 |

注：有缩写代码或压缩代码的情况下，行覆盖率的颗粒度可能大于语句覆盖率，因为可允许一行代码包括多条语句。

还会生成一个 coverage 文件夹，点击 index.html 就会打开一个详细的测试报告，可根据测试报告的详细信息完善单元测试的细节。

### 使用：认识常见匹配器

上述代码都有用到 expect()、test()和 toBe()三个函数，它们组合起来表示一个测试用例中运行结果匹配期待结果，检验是否符合某种匹配状态。该匹配状态又称匹配器，可能是值相等、值全等、满足范围值等。

#### toBe()

检查对象是否全等某值，类似===。

#### toBeLessThan()

检查对象是否小于某值，类似<。

#### toBeCloseTo()

检查对象是否约等于某值，类似 ≈。

#### toEqual()

测试两个对象的值是否相等，只对比值，不对比引用地址。该函数用在引用类型中更佳，例如数组与对象。

```js
test("两数组的内容是否相等", () => {
  const arr1 = [0, 1, 2];
  const arr2 = [0, 1, 2];
  expect(arr1).toEqual(arr2); // 通过
});
```

#### toBeUndefined()

检查对象是否为 undefined。

#### toBeTruthy() toBeFalsy()

toBeTruthy() 检查对象转换为布尔后是否为 true。
toBeFalsy() 检查对象转换为布尔后是否为 false。

```js
test("转换值是否为 true", () => {
  expect(undefined).toBeTruthy(); // 不通过
  expect(null).toBeTruthy(); // 不通过
  expect("").toBeTruthy(); // 不通过
  expect(0).toBeTruthy(); // 不通过
  expect(false).toBeTruthy(); // 不通过
});
```

#### toMatch()

检查对象是否包括字符串或匹配正则，类似字符串的 includes()与 match()。

#### toContain()

检查对象是否被数组包括，类似数组的 includes()。

## 总结

编写测试用例需要花费很多时间，对于一些大型项目或开源项目，像组件库与工具库这些业务性较强的类库，单元测试还是很有必要接入的；对于一些小型项目或 KPI 项目，就需考虑考虑了。
